{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation d'observations de loi multinomiale "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous souhaitons simuler des observations d'une loi multinomiale: \n",
    "\n",
    "Considérons l'expérience où on extrait $n$ boules de $k$ différentes couleurs d'une urne avec remise. Les boules de la même couleur sont équivalents. Soit $X_i$ la variable qui compte le nombre de balles de couleur $i$ extraites ($i = 1, \\cdots, k$), et soit $p_i$ la probabilité d'extraire une boule de couleur $i$. La probabilité de cette loi multinomiale est alors donnée part :\n",
    "\n",
    "<math> \\begin{align}\n",
    "f(x_1,\\ldots,x_k;n,p_1,\\ldots,p_k) & {} = \\mathbb{P}(X_1 = x_1, \\dots, X_k = x_k) \\\\\n",
    "& {} = \\begin{cases} { \\displaystyle {n! \\over x_1!\\cdots x_k!}p_1^{x_1}\\times\\cdots\\times p_k^{x_k}}, \\quad &\n",
    "\\text{quand } \\sum_{i=1}^k x_i=n \\\\  \\\\\n",
    "0 & \\text{sinon} \\end{cases}\n",
    "\\end{align}\n",
    "</math>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation avec numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "CPU times: user 558 µs, sys: 368 µs, total: 926 µs\n",
      "Wall time: 513 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Genere 100 observations multinomiale de paramètre n=1 milliard et p = [1./3,1./4,1./6,3./12]\n",
    "mult = np.random.multinomial(1e9, [1./3,1./4,1./6,3./12], size=100)\n",
    "print(mult.shape)\n",
    "mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33333144, 0.25000606, 0.16666069, 0.2500018 ],\n",
       "       [0.33333216, 0.2499936 , 0.16666698, 0.25000726],\n",
       "       [0.33334131, 0.24999615, 0.16666678, 0.24999575],\n",
       "       [0.3333655 , 0.24998065, 0.16666325, 0.2499906 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On retrouve empiriquement les probs théoriques\n",
    "(mult/1e9)[:4,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme de simulation : méthode de la fonction inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir une loi multinomiale comme la répétion de n expériences indépendantes à k issues possibles dont on a ensuite rassemblé les issues (compté le nombre de boules pour chaque couleur). On peut donc simuler chacune des expériences indépendamment. \n",
    "\n",
    "Pour générer une variable aléatoire discrète prenant pour valeur $1, \\cdots, k$ avec proba $p_1, \\cdots, p_k$ il suffit d'appliquer la méthode de la fonction inverse (avec inverse généralisée comme on est dans le cas discret). Plus clairement, on génére $U$ une variable aléatoire uniforme sur $[0,1]$ et on regarde dans quel \"bins\" on tombe, i.e, on calcule :  \n",
    "\n",
    "$$j = \\min \\left\\{ j' \\in \\{1,\\dots,k\\} : \\left(\\sum_{i=1}^{j'} p_i\\right) - U \\geq 0 \\right\\}$$\n",
    "\n",
    "En répétant cette algorithme n fois et en rassamblant les issus on obtient une observation multinomiale. Nous présentons dans la cellule suivante l'algorithme \"multinomial1\" quie met en place cette statégie sans finesse. L'algorithme \"multinomial2\" est une version vectorisée, plus difficile à déchiffrer mais beaucoup plus rapide. Dans tous les cas on ne pourra pas battre les algos de numpy qui sont implémenté directement en C++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial1(n,prob,size=1,seed=42):\n",
    "    \"\"\"size = nombre d'observations multinomiale\n",
    "    seed permet de fixer l'aléatoire\n",
    "    \n",
    "    Attention, meme si le vecteur en entré n'est pas trié, \n",
    "    la sortie est toujours trié par ordre décroissant\"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "     \n",
    "    if abs(np.sum(prob)-1)>10e-16:\n",
    "        return \"Probabilités ne somment pas à 1\"\n",
    "    \n",
    "    prob = np.sort(prob)[::-1] #tri par ordre décroissant, plus rapide\n",
    "    \n",
    "    u = np.random.uniform(size=n*size).reshape(size,n)\n",
    "    output = np.zeros((size,len(prob)))\n",
    "    for step in range(size):\n",
    "        for el in u[step,:]:\n",
    "            #pour chaque u on rejoute +1 pour la bins dans laquelle il tome\n",
    "            output[step,get_bin(el,prob)] += 1\n",
    "        \n",
    "    return output\n",
    "    \n",
    "    \n",
    "def get_bin(u,prob):\n",
    "    '''Permet d'obtenir la bins dans laquelle tome un element selon un vecteur de proba'''\n",
    "    cumprob = np.cumsum(prob)\n",
    "    for i,p in enumerate(cumprob):\n",
    "        if u<p:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33439 0.24914 0.25124 0.16523]\n",
      " [0.33104 0.25022 0.25053 0.16821]\n",
      " [0.333   0.24922 0.25067 0.16711]\n",
      " [0.33536 0.2493  0.24995 0.16539]\n",
      " [0.33107 0.25053 0.25142 0.16698]\n",
      " [0.33333 0.25208 0.24891 0.16568]\n",
      " [0.33335 0.24986 0.24943 0.16736]\n",
      " [0.33383 0.24946 0.24986 0.16685]\n",
      " [0.33204 0.24662 0.25257 0.16877]\n",
      " [0.33277 0.25164 0.25031 0.16528]\n",
      " [0.3342  0.25105 0.24793 0.16682]\n",
      " [0.33412 0.25078 0.25078 0.16432]\n",
      " [0.33378 0.24883 0.25002 0.16737]\n",
      " [0.33237 0.25331 0.25051 0.16381]\n",
      " [0.33521 0.25034 0.24991 0.16454]\n",
      " [0.33262 0.252   0.24778 0.1676 ]\n",
      " [0.33324 0.25268 0.24921 0.16487]\n",
      " [0.33354 0.25041 0.24819 0.16786]\n",
      " [0.33592 0.24857 0.25026 0.16525]\n",
      " [0.33273 0.24957 0.25237 0.16533]]\n",
      "CPU times: user 4.98 s, sys: 132 ms, total: 5.11 s\n",
      "Wall time: 5.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = int(1e5)\n",
    "test = multinomial1(n,np.array([1./3,1./4,1./6,3./12]),size=20)\n",
    "print(test/float(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial2(n,prob,size=1,seed=42):\n",
    "    \"\"\"Genere une loi multinomiale, approche plus vectorielle que la premiere\n",
    "    size = nombre d'observations multinomiale\n",
    "    seed permet de fixer l'aléatoire\n",
    "    \n",
    "    Attention, meme si le vecteur en entré n'est pas trié, \n",
    "    la sortie est toujours trié par ordre décroissant\"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "     \n",
    "    if abs(np.sum(prob)-1)>10e-16:\n",
    "        return \"Probabilités ne somment pas à 1\"\n",
    "    \n",
    "    prob = np.sort(prob)[::-1] \n",
    "    \n",
    "    u = np.random.uniform(size=n*size).reshape(size,n)\n",
    "    output = np.zeros((size,len(prob)))\n",
    "    \n",
    "    cprob = np.cumsum(prob)\n",
    "    \n",
    "    for i,p in enumerate(cprob):\n",
    "        if i==0:\n",
    "            output[:,i] = (u<cprob[i]).sum(axis=1)\n",
    "        else : \n",
    "            output[:,i] = ((u<cprob[i]) & (u>=cprob[i-1])).sum(axis=1)\n",
    "   # output = np.concatenate((output[:,0].reshape(-1,1),np.diff(output,axis=1)),axis=1)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33439 0.24914 0.25124 0.16523]\n",
      " [0.33104 0.25022 0.25053 0.16821]\n",
      " [0.333   0.24922 0.25067 0.16711]\n",
      " [0.33536 0.2493  0.24995 0.16539]]\n",
      "CPU times: user 42.4 ms, sys: 5.14 ms, total: 47.6 ms\n",
      "Wall time: 56.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = int(1e5)\n",
    "test = multinomial2(n,np.array([1./3,1./4,1./6,3./12]),size=20)\n",
    "print((test/float(n))[:4,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beaucoup plus rapide !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy example for CE Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cet example correspond à l'example 2.2 de \"A Tutorial on the Cross-Entropy Method\". On reproduit les mêmes résultats avec $n = 10$, $y = (1,1,1,1,1,0,0,0,0,0)$, $N=50$, $\\rho=0.1$ et initialisation avec des Bernouilli uniformes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyCrossEntropy(object):\n",
    "    \"\"\"Méthode de la cross entropie pour l'exemple jouet introduit dans  \n",
    "        De Boer, Kroese, Mannor and Rubinstein (2003). \n",
    "        A Tutorial on the Cross-Entropy Method. Annals of Operations \n",
    "    \n",
    "    Attributs:\n",
    "        y: vecteur binaire dont on veut approcher les éléments.\n",
    "        N: entier, nombre de simulations pour chaque étape\n",
    "        perc: entier, correspond au percentile fixé dans l'algo   \n",
    "        seed: entier, pour fixer l'aléatoire.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,y,N,perc=90, seed=42):\n",
    "        \"\"\"Initialise la classe ToyCrossEntropy.\"\"\"\n",
    "        self.y = y\n",
    "        self.n = len(y)\n",
    "        self.N = N\n",
    "        self.perc = perc\n",
    "        self.seed = seed\n",
    "        \n",
    "    def Bernouilli(self,p):\n",
    "        '''Permet de simuler une matrice de taille n*len(p) où p=(p_1,...,p_n)\n",
    "        Chaque colonne est composé de n Bernouilli(p_j) indépendantes'''\n",
    "        \n",
    "        return np.array([np.random.binomial(1,prob,size=self.N) for prob in p]).T\n",
    "\n",
    "    def S(self,x):\n",
    "        '''retourne le nombre de \"match\" entre deux vecteurs binaires'''\n",
    "        \n",
    "        return len(x) - np.sum(np.abs(x-self.y))\n",
    "\n",
    "    def update(self,x,score,q):\n",
    "        '''fonction permettant d'update les probabilités des bernouilli\n",
    "        Lire l'article pour plus de détails'''\n",
    "        \n",
    "        return np.sum((score>=q)*(x))/float(np.sum((score>=q)))\n",
    "\n",
    "    def CE_fit(self):\n",
    "        #fixe aléa\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        \n",
    "        #initialise with Bernouilli(0.5)\n",
    "        p_init = np.tile(0.5,self.n)\n",
    "        \n",
    "        while(self.S(p_init)!=self.n):\n",
    "\n",
    "\n",
    "            #generate N vectors of bernouilli variables with probabilities p_init\n",
    "            x = self.Bernouilli(p_init)\n",
    "            #compute score for each vectors\n",
    "            score = np.apply_along_axis(lambda x: self.S(x),1,x)\n",
    "            #calcul du quantile\n",
    "            q = np.percentile(score,self.perc)\n",
    "            print([int(q),np.round(p_init,2)])\n",
    "\n",
    "            #update of probabilities\n",
    "            p_init = np.apply_along_axis(lambda x, score=score, q=q: self.update(x,score,q),0,x)\n",
    "\n",
    "        print([q,np.round(p_init,2)])\n",
    "        \n",
    "        return \"Convergence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])]\n",
      "[8, array([0.56, 0.78, 0.78, 1.  , 0.78, 0.33, 0.33, 0.22, 0.44, 0.22])]\n",
      "[10, array([0.8, 1. , 1. , 1. , 1. , 0. , 0. , 0. , 0. , 0. ])]\n",
      "[10.0, array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Convergence'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=[1,1,1,1,1,0,0,0,0,0]\n",
    "N=50\n",
    "toy = ToyCrossEntropy(y,N)\n",
    "toy.CE_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSE problem using cross entropy method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Extracted from \"A Tutorial on the Cross-Entropy Method\")\n",
    "The travelling salesman problem (TSP) can be formulated as follows. Consider a weighted graph $G$ with $n$ nodes, labelled $1, 2, \\cdots, n$. The nodes represent cities, and the edges represent the roads between the cities. Each edge from $i$ to $j$ has weight or cost $c_{i,j}$, representing the length of the road. The problem is to find the shortest tour that visits all the cities exactly once (except the starting city, which is also the terminating city).\n",
    "\n",
    "Without loss of generality, let us assume that the graph is complete (each nodes are connected to each other), and that some of the weights may be $+\\infty$. Let $\\chi$ be the set of all possible tours and let $S(x)$ the total length of tour $x \\in \\chi$. We can represent each tour via a permutation of $(1, \\cdots , n)$. For example for $n = 4$, the permutation $(1, 3, 2, 4)$ represents the tour 1→3→2→4→1. Infact, we may as well represent a tour via a permutation $x = (x_1,\\cdots,x_n)$ with $x_1 = 1$. From now on we identify a tour with its corresponding permutation, where $x_1 = 1$. We may now formulate the TSP as follows.\n",
    "\n",
    "$$\\min_{x\\in \\chi} S(x)  = \\min_{x\\in \\chi} \\sum_{i=1}^{n-1} c_{x_i,x_{i+1}} + c_{x_n,x_1}  $$\n",
    "\n",
    "Note that the number of elements $|\\chi| = (n-1)!$. We are looking for $x^*$ the solution of the problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
